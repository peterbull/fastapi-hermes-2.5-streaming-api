{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import argparse\n",
    "from llama_cpp import Llama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"-m\", \"--model\", type=str,\n",
    "                    default=\"../models/mistral-7b-instruct-v0.1.Q4_K_M.gguf\")\n",
    "parser.add_argument(\"-pt\", \"--prompt\", type=str,\n",
    "                    default=\"<s>[INST]{prompt}[/INST]\")\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = args.prompt\n",
    "\n",
    "print(\"Loading model \" + args.model)\n",
    "llm = Llama(model_path=args.model, n_gpu_layers=35, n_ctx=4096,\n",
    "            temp=0.7, repeat_penalty=1.1, verbose=False)\n",
    "\n",
    "# llm(\"Question: What are the names of the planets in the solar system? Answer: \", max_tokens=48,stop=[\"Q:\", \"\\n\"],stream=True)\n",
    "stream = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function - Print response output in chunks (stream)\n",
    "def printresponse(response):\n",
    "    completion_text = ''\n",
    "    # iterate through the stream of events and print it\n",
    "    print(f\"Bot:\", end=\"\", flush=True)\n",
    "    for event in response:\n",
    "        event_text = event['choices'][0]['text']\n",
    "        completion_text += event_text\n",
    "        print(f\"{event_text}\", end=\"\", flush=True)\n",
    "\n",
    "    print(\"\", flush=True)\n",
    "    # remember context\n",
    "    # context.append({\"role\": \"assistant\", \"content\" : completion_text})\n",
    "    return completion_text\n",
    "\n",
    "# printresponse(stream)\n",
    "\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        u_input = input(\"-> \")\n",
    "\n",
    "        prompt = prompt_template.format(prompt=u_input)\n",
    "        stream = llm(prompt, max_tokens=512, stream=True)\n",
    "        response = printresponse(stream)\n",
    "        print()\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n..(Response interrupted).\")  # continue\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
